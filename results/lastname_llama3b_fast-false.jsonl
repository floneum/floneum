[2m2025-09-11T01:36:36.788276Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:36:36.788322Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:37:03.338367Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:37:03.338400Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:37:03.679407Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:37:03.679522Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:37:03.963187Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
[2m2025-09-11T01:37:03.963293Z[0m [32m INFO[0m [2mhf_hub[0m[2m:[0m Token file not found "/Users/sankha/.cache/huggingface/token"    
{"generation":0,"metadata":{"sampler_time":{"secs":0,"nanos":58842},"constraint_time":{"secs":0,"nanos":236872335},"parser_time":{"secs":0,"nanos":356708},"transformer_time":{"secs":0,"nanos":645208417},"trie_time":{"secs":0,"nanos":38870},"total_time":{"secs":1,"nanos":90671167}},"pass":false,"entropy":0.0,"entropy_diff":1000.0,"tokenization_error":true,"tokens_after_tokenization_error":2,"result":"(define-fun f ((name String)) String (str.++ (str.++ name \" \") (str.substr name 0 1))","tokens":[69647,2269,359,282,1819,609,935,595,935,320,496,13,1044,320,496,13,1044,836,330,12590,320,496,18497,836,220,15,220,16,8,8]}
{"generation":1,"metadata":{"sampler_time":{"secs":0,"nanos":10167},"constraint_time":{"secs":0,"nanos":470041},"parser_time":{"secs":0,"nanos":119876},"transformer_time":{"secs":0,"nanos":285473583},"trie_time":{"secs":0,"nanos":18668},"total_time":{"secs":0,"nanos":370805292}},"pass":false,"entropy":2.330021976126732,"entropy_diff":-2.330021976126732,"tokenization_error":true,"tokens_after_tokenization_error":2,"result":"(define-fun f ((name String)) String (str.++ name \" \")","tokens":[69647,2269,359,282,1819,609,935,595,935,320,496,13,1044,836,330,330,8]}
