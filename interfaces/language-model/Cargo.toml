[package]
name = "kalosm-language-model"
version = "0.4.0"
edition = "2021"
description = "A common interface for language models/transformers "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["ai", "llm", "llama", "mistral", "nlp"]

[dependencies]
futures-util = "0.3.28"
futures-channel = "0.3.31"
llm-samplers = { workspace = true, optional = true }
rand = "0.8.5"
serde = { version = "1.0.163", features = ["derive"], optional = true }
tracing = "0.1.37"
kalosm-sample = { workspace = true }
kalosm-model-types.workspace = true
thiserror.workspace = true
lru = { version = "0.12.3", optional = true }
reqwest = { version = "0.12.12", features = ["json"], optional = true }
serde_json = { version = "1.0.134", optional = true }
reqwest-eventsource = { version = "0.6.0", optional = true }
anyhow = { workspace = true, optional = true }
async-lock = "3.4.0"

[dev-dependencies]
tokio = { version = "1.28.1", features = ["full"] }
kalosm = { workspace = true, features = ["language"] }
kalosm-learning = { workspace = true }
pretty_assertions = "1.4.1"
postcard = { version = "1.0.8", features = ["use-std"] }
anyhow = { workspace = true }

[features]
default = ["cache"]
anthropic = ["dep:reqwest", "dep:serde_json", "dep:reqwest-eventsource"]
openai = ["dep:reqwest", "dep:serde_json", "dep:reqwest-eventsource"]
remote = ["anthropic", "openai"]
serde = ["dep:serde"]
cache = ["serde", "dep:lru"]
sample = ["dep:llm-samplers", "dep:anyhow"]

[package.metadata.docs.rs]
# Features to pass to Cargo (default: [])
features = ["remote"]
