use fusor_core::*;
use naga::front::wgsl;
use naga::back::msl;
use naga::valid::ValidationFlags;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::fmt().init();

    let device = Device::new().await?;

    // Create sample matrices for matmul
    let data_a = [[1.0, 2.0, 3.0, 4.0],
                  [5.0, 6.0, 7.0, 8.0],
                  [9.0, 10.0, 11.0, 12.0],
                  [13.0, 14.0, 15.0, 16.0]];
    
    let data_b = [[1.0, 0.0, 0.0, 1.0],
                  [0.0, 1.0, 1.0, 0.0], 
                  [1.0, 1.0, 0.0, 0.0],
                  [0.0, 0.0, 1.0, 1.0]];
    
    let tensor_a = Tensor::new(&device, &data_a);
    let tensor_b = Tensor::new(&device, &data_b);
    
    println!("Performing matrix multiplication to trigger kernel generation...");
    println!("Matrix A: 4x4");
    println!("Matrix B: 4x4");
    println!("Result: 4x4");
    println!();
    
    // Perform matmul which will internally generate and compile the kernel
    let result = tensor_a.mat_mul(&tensor_b);
    let _result_data = result.as_slice().await?;
    
    println!("MatMul operation completed successfully!");
    println!("The kernel has been generated and executed.");
    println!();
    
    // Since we can't directly access the kernel source from the public API,
    // let's manually show what the kernel would look like based on the implementation
    let kernel_source = generate_sample_kernel();
    
    println!("Sample WGSL MatMul Kernel (based on the implementation):");
    println!("=======================================================");
    println!("{}", kernel_source);
    
    // Now let's use wgpu's naga to translate to Metal
    println!("\nTranslating to Metal Shading Language...");
    println!("========================================");
    
    translate_to_metal(&kernel_source)?;
    
    Ok(())
}

fn generate_sample_kernel() -> String {
    // This represents a simplified version of the actual kernel generated by the matmul implementation
    r#"@group(0) @binding(0) var<storage, read> i_0: array<f32>;
struct Tensor1Info {
    offset: u32,
    stride_0: u32,
    shape_0: u32,
    stride_1: u32,
    shape_1: u32,
};
@group(0) @binding(1) var<uniform> i_1: Tensor1Info;
@group(0) @binding(2) var<storage, read> i_2: array<f32>;
struct Tensor3Info {
    offset: u32,
    stride_0: u32,
    shape_0: u32,
    stride_1: u32,
    shape_1: u32,
};
@group(0) @binding(3) var<uniform> i_3: Tensor3Info;
@group(0) @binding(4) var<storage, read_write> i_4: array<f32>;
struct Tensor5Info {
    offset: u32,
    stride_0: u32,
    shape_0: u32,
    stride_1: u32,
    shape_1: u32,
};
@group(0) @binding(5) var<uniform> i_5: Tensor5Info;
var<workgroup> g_0: array<f32, 1152>;
var<workgroup> g_1: array<f32, 576>;
const BLOCKSIZE: u32 = 128u;
@compute @workgroup_size(128, 1, 1)
fn main(@builtin(global_invocation_id) global_id: vec3<u32>, @builtin(local_invocation_index) workgroup_local_id: u32, @builtin(workgroup_id) workgroup_index: vec3<u32>) {
{let cRow = workgroup_index.y;
let cCol = workgroup_index.x;
var block_batch = workgroup_index.z;
let totalResultsBlocktile = 64u * 32u;
let numThreadsBlocktile = totalResultsBlocktile / (4u * 4u);
let threadCol = workgroup_local_id % (32u / 4u);
let threadRow = workgroup_local_id / (32u / 4u);
let a_start_index = 
i_1.offset;
let b_start_index = 
i_3.offset;
let c_start_index = 
i_5.offset;
let innerRowA = workgroup_local_id / 8u;
let innerColA = workgroup_local_id % 8u;
let innerRowB = workgroup_local_id / 32u;
let innerColB = workgroup_local_id % 32u;
var threadResults: array<f32, 16>;
var regM: vec4<f32>;
var regN: vec4<f32>;
// Advanced tile computation with branch prediction hints
let tiles = (i_1.shape_1 + 8u - 1u) / 8u;
let tilesIsPowerOf2 = (tiles & (tiles - 1u)) == 0u;
let maxTileSize = 8u;
var buf: u32 = 0u;
let aTileSize = 64u * 9u;
let bTileSize = 32u * 9u;
let aSwizzle = 1u;
let bSwizzle = 1u;
if (tiles > 0u) {
    let bkIdx = 0u;
    let aBase = buf * aTileSize;
    let bBase = buf * bTileSize;
    let fullK = (bkIdx + 8u) <= i_1.shape_1;
    let fullA = (((cRow + 1u) * 64u) <= i_1.shape_0) && fullK;
    let fullB = (((cCol + 1u) * 32u) <= i_3.shape_1) && fullK;
    if (fullA) {
        { let row_raw = innerRowA + 0u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        { let row_raw = innerRowA + 1u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        { let row_raw = innerRowA + 2u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        { let row_raw = innerRowA + 3u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
    } else {
        { let row_raw = innerRowA + 0u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        { let row_raw = innerRowA + 1u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        { let row_raw = innerRowA + 2u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        { let row_raw = innerRowA + 3u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBase + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
    }
    if (fullB) {
        { let row_raw = innerRowB + 0u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row = bkIdx + row_raw; let b_col = cCol * 32u + col_raw; var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; g_1[bBase + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
        { let row_raw = innerRowB + 1u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row = bkIdx + row_raw; let b_col = cCol * 32u + col_raw; var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; g_1[bBase + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
    } else {
        { let row_raw = innerRowB + 0u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row_global = bkIdx + row_raw; let b_col_global = cCol * 32u + col_raw; let b_row = min(b_row_global, i_1.shape_1 - 1u); let b_col = min(b_col_global, i_3.shape_1 - 1u); var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; b_val = select(0.0, b_val, (b_row_global < i_1.shape_1 && b_col_global < i_3.shape_1)); g_1[bBase + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
        { let row_raw = innerRowB + 1u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row_global = bkIdx + row_raw; let b_col_global = cCol * 32u + col_raw; let b_row = min(b_row_global, i_1.shape_1 - 1u); let b_col = min(b_col_global, i_3.shape_1 - 1u); var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; b_val = select(0.0, b_val, (b_row_global < i_1.shape_1 && b_col_global < i_3.shape_1)); g_1[bBase + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
    }
}
workgroupBarrier();
for (var t = 0u; t < tiles; t++) {
    let aBase = buf * aTileSize;
    let bBase = buf * bTileSize;
    // Async prefetch optimization - prepare next tile info early
    let hasNextTile = ((t + 1u) < tiles);
    let nextBkIdx = select(0u, (t + 1u) * 8u, hasNextTile);
    let nextBuf = 1u - buf;
    for (var dotIdx = 0u; dotIdx < 8u; dotIdx++) {
        let reg_m_offset = aBase + threadRow * 4u * (8u + aSwizzle) + dotIdx;
            // Advanced vectorized load with swizzling
            regM = vec4<f32>(g_0[reg_m_offset], g_0[reg_m_offset + 9u], g_0[reg_m_offset + 18u], g_0[reg_m_offset + 27u]);
        let reg_n_offset = bBase + threadCol * 4u * (8u + bSwizzle) + dotIdx;
            // Advanced vectorized load with swizzling
            regN = vec4<f32>(g_1[reg_n_offset], g_1[reg_n_offset + 9u], g_1[reg_n_offset + 18u], g_1[reg_n_offset + 27u]);
        // Aggressive register blocking with ILP optimization
        let result_0 = regM[0] * regN;
        let result_1 = regM[1] * regN;
        let result_2 = regM[2] * regN;
        let result_3 = regM[3] * regN;
        // Column 0 accumulation with ILP
        threadResults[0 * 4u + 0] += result_0[0];
        threadResults[1 * 4u + 0] += result_1[0];
        threadResults[2 * 4u + 0] += result_2[0];
        threadResults[3 * 4u + 0] += result_3[0];
        // Column 1 accumulation with ILP
        threadResults[0 * 4u + 1] += result_0[1];
        threadResults[1 * 4u + 1] += result_1[1];
        threadResults[2 * 4u + 1] += result_2[1];
        threadResults[3 * 4u + 1] += result_3[1];
        // Column 2 accumulation with ILP
        threadResults[0 * 4u + 2] += result_0[2];
        threadResults[1 * 4u + 2] += result_1[2];
        threadResults[2 * 4u + 2] += result_2[2];
        threadResults[3 * 4u + 2] += result_3[2];
        // Early async prefetch trigger - start loading next tile
        if (hasNextTile && dotIdx == (8u / 2u)) {
            // Async memory prefetch hints for next iteration
            // This helps overlap memory access with computation
        }
        // Column 3 accumulation with ILP
        threadResults[0 * 4u + 3] += result_0[3];
        threadResults[1 * 4u + 3] += result_1[3];
        threadResults[2 * 4u + 3] += result_2[3];
        threadResults[3 * 4u + 3] += result_3[3];
    }
    if ((t + 1u) < tiles) {
        let bkIdx = (t + 1u) * 8u;
        let nextBuf: u32 = 1u - buf;
        let aBaseN = nextBuf * aTileSize;
        let bBaseN = nextBuf * bTileSize;
        let fullK = (bkIdx + 8u) <= i_1.shape_1;
        let fullA = (((cRow + 1u) * 64u) <= i_1.shape_0) && fullK;
        let fullB = (((cCol + 1u) * 32u) <= i_3.shape_1) && fullK;
        if (fullA) {
            { let row_raw = innerRowA + 0u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
            { let row_raw = innerRowA + 1u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
            { let row_raw = innerRowA + 2u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
            { let row_raw = innerRowA + 3u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row = cRow * 64u + row_raw; let a_col = bkIdx + col_raw; var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        } else {
            { let row_raw = innerRowA + 0u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
            { let row_raw = innerRowA + 1u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
            { let row_raw = innerRowA + 2u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
            { let row_raw = innerRowA + 3u * (numThreadsBlocktile / 8u); let col_raw = innerColA; let a_row_global = cRow * 64u + row_raw; let a_col_global = bkIdx + col_raw; let a_row = min(a_row_global, i_1.shape_0 - 1u); let a_col = min(a_col_global, i_1.shape_1 - 1u); var a_val = 
i_0[a_start_index + a_row * i_1.shape_1 + a_col]; a_val = select(0.0, a_val, (a_row_global < i_1.shape_0 && a_col_global < i_1.shape_1)); g_0[aBaseN + row_raw * (8u + aSwizzle) + col_raw] = a_val; }
        }
        if (fullB) {
            { let row_raw = innerRowB + 0u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row = bkIdx + row_raw; let b_col = cCol * 32u + col_raw; var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; g_1[bBaseN + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
            { let row_raw = innerRowB + 1u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row = bkIdx + row_raw; let b_col = cCol * 32u + col_raw; var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; g_1[bBaseN + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
        } else {
            { let row_raw = innerRowB + 0u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row_global = bkIdx + row_raw; let b_col_global = cCol * 32u + col_raw; let b_row = min(b_row_global, i_1.shape_1 - 1u); let b_col = min(b_col_global, i_3.shape_1 - 1u); var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; b_val = select(0.0, b_val, (b_row_global < i_1.shape_1 && b_col_global < i_3.shape_1)); g_1[bBaseN + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
            { let row_raw = innerRowB + 1u * (numThreadsBlocktile / 32u); let col_raw = innerColB; let b_row_global = bkIdx + row_raw; let b_col_global = cCol * 32u + col_raw; let b_row = min(b_row_global, i_1.shape_1 - 1u); let b_col = min(b_col_global, i_3.shape_1 - 1u); var b_val = 
i_2[b_start_index + b_row * i_3.shape_1 + b_col]; b_val = select(0.0, b_val, (b_row_global < i_1.shape_1 && b_col_global < i_3.shape_1)); g_1[bBaseN + col_raw * (8u + bSwizzle) + row_raw] = b_val; }
        }
    }
    workgroupBarrier();
    buf = 1u - buf;
}
let outRowOffset = threadRow * 4u + cRow * 64u;
let outColOffset = threadCol * 4u + cCol * 32u;
if (outRowOffset < i_1.shape_0 && outColOffset < i_3.shape_1) {
let outRow0 = min(outRowOffset + 0, i_1.shape_0 - 1);
let outRow1 = min(outRowOffset + 1, i_1.shape_0 - 1);
let outRow2 = min(outRowOffset + 2, i_1.shape_0 - 1);
let outRow3 = min(outRowOffset + 3, i_1.shape_0 - 1);
let outCol0 = min(outColOffset + 0, i_3.shape_1 - 1);
let outCol1 = min(outColOffset + 1, i_3.shape_1 - 1);
let outCol2 = min(outColOffset + 2, i_3.shape_1 - 1);
let outCol3 = min(outColOffset + 3, i_3.shape_1 - 1);
i_4[c_start_index + outRow0 * i_3.shape_1 + outCol0] = threadResults[(outRow0 - outRowOffset) * 4u + (outCol0 - outColOffset)];
i_4[c_start_index + outRow0 * i_3.shape_1 + outCol1] = threadResults[(outRow0 - outRowOffset) * 4u + (outCol1 - outColOffset)];
i_4[c_start_index + outRow0 * i_3.shape_1 + outCol2] = threadResults[(outRow0 - outRowOffset) * 4u + (outCol2 - outColOffset)];
i_4[c_start_index + outRow0 * i_3.shape_1 + outCol3] = threadResults[(outRow0 - outRowOffset) * 4u + (outCol3 - outColOffset)];
i_4[c_start_index + outRow1 * i_3.shape_1 + outCol0] = threadResults[(outRow1 - outRowOffset) * 4u + (outCol0 - outColOffset)];
i_4[c_start_index + outRow1 * i_3.shape_1 + outCol1] = threadResults[(outRow1 - outRowOffset) * 4u + (outCol1 - outColOffset)];
i_4[c_start_index + outRow1 * i_3.shape_1 + outCol2] = threadResults[(outRow1 - outRowOffset) * 4u + (outCol2 - outColOffset)];
i_4[c_start_index + outRow1 * i_3.shape_1 + outCol3] = threadResults[(outRow1 - outRowOffset) * 4u + (outCol3 - outColOffset)];
i_4[c_start_index + outRow2 * i_3.shape_1 + outCol0] = threadResults[(outRow2 - outRowOffset) * 4u + (outCol0 - outColOffset)];
i_4[c_start_index + outRow2 * i_3.shape_1 + outCol1] = threadResults[(outRow2 - outRowOffset) * 4u + (outCol1 - outColOffset)];
i_4[c_start_index + outRow2 * i_3.shape_1 + outCol2] = threadResults[(outRow2 - outRowOffset) * 4u + (outCol2 - outColOffset)];
i_4[c_start_index + outRow2 * i_3.shape_1 + outCol3] = threadResults[(outRow2 - outRowOffset) * 4u + (outCol3 - outColOffset)];
i_4[c_start_index + outRow3 * i_3.shape_1 + outCol0] = threadResults[(outRow3 - outRowOffset) * 4u + (outCol0 - outColOffset)];
i_4[c_start_index + outRow3 * i_3.shape_1 + outCol1] = threadResults[(outRow3 - outRowOffset) * 4u + (outCol1 - outColOffset)];
i_4[c_start_index + outRow3 * i_3.shape_1 + outCol2] = threadResults[(outRow3 - outRowOffset) * 4u + (outCol2 - outColOffset)];
i_4[c_start_index + outRow3 * i_3.shape_1 + outCol3] = threadResults[(outRow3 - outRowOffset) * 4u + (outCol3 - outColOffset)];
}
}
}"#.to_string()
}

fn translate_to_metal(wgsl_code: &str) -> Result<(), Box<dyn std::error::Error>> {
    let module = match wgsl::parse_str(wgsl_code) {
        Ok(module) => module,
        Err(e) => {
            eprintln!("Failed to parse WGSL: {:?}", e);
            return Ok(());
        }
    };
    
    // Validate the module
    let mut validator = naga::valid::Validator::new(
        ValidationFlags::all(),
        naga::valid::Capabilities::all()
    );
    let module_info = match validator.validate(&module) {
        Ok(info) => info,
        Err(e) => {
            eprintln!("Module validation failed: {:?}", e);
            return Ok(());
        }
    };
    
    // Translate to Metal
    let options = msl::Options {
        lang_version: (3, 0),
        zero_initialize_workgroup_memory: false,
        ..Default::default()
    };
    let pipeline_options = msl::PipelineOptions::default();
    
    let mut output = String::new();
    let mut writer = msl::Writer::new(&mut output);
    match writer.write(&module, &module_info, &options, &pipeline_options) {
        Ok(_) => {
            println!("Metal Shading Language Translation:");
            println!("==================================");
            println!("{}", output);
            
            // Analyze the Metal version for optimization insights
            println!("\nOptimization Analysis:");
            println!("=====================");
            analyze_metal_code(&output);
        }
        Err(e) => {
            eprintln!("Failed to translate to Metal: {:?}", e);
        }
    }
    
    Ok(())
}

fn analyze_metal_code(metal_code: &str) {
    let lines: Vec<&str> = metal_code.lines().collect();
    
    println!("Key Metal-specific optimizations observed:");
    
    // Look for threadgroup memory usage
    let threadgroup_count = lines.iter().filter(|line| line.contains("threadgroup")).count();
    if threadgroup_count > 0 {
        println!("- {} uses of threadgroup memory detected", threadgroup_count);
    }
    
    // Look for SIMD operations
    let simd_count = lines.iter().filter(|line| line.contains("simd")).count();
    if simd_count > 0 {
        println!("- {} SIMD operations detected", simd_count);
    }
    
    // Look for thread positions
    let thread_pos_count = lines.iter().filter(|line| 
        line.contains("thread_position_in_threadgroup") || 
        line.contains("threadgroup_position_in_grid") ||
        line.contains("thread_position_in_grid")
    ).count();
    if thread_pos_count > 0 {
        println!("- {} thread position queries detected", thread_pos_count);
    }
    
    // Look for barrier synchronization
    let barrier_count = lines.iter().filter(|line| line.contains("threadgroup_barrier")).count();
    if barrier_count > 0 {
        println!("- {} threadgroup barriers detected", barrier_count);
    }
    
    // Look for matrix-multiply-accumulate operations
    let fma_count = lines.iter().filter(|line| line.contains("fma") || line.contains("mad")).count();
    if fma_count > 0 {
        println!("- {} fused multiply-add operations detected", fma_count);
    }
    
    // Look for vector operations
    let vec_count = lines.iter().filter(|line| line.contains("float4") || line.contains("vec4")).count();
    if vec_count > 0 {
        println!("- {} vector operations detected", vec_count);
    }
    
    println!("\nSuggestions for WGPU optimization based on Metal translation:");
    println!("1. Memory Access Patterns:");
    println!("   - Use vectorized loads (vec4<f32>) for better memory bandwidth");
    println!("   - Ensure coalesced memory access patterns");
    println!("   - Consider memory layout transformations (row/column major)");
    
    println!("2. Compute Optimizations:");
    println!("   - Leverage FMA (fused multiply-add) operations where available");
    println!("   - Use subgroup operations for cross-lane communication");
    println!("   - Optimize register usage and minimize spilling");
    
    println!("3. Workgroup Optimizations:");
    println!("   - Maximize occupancy by balancing shared memory and register usage");
    println!("   - Use threadgroup barriers strategically");
    println!("   - Consider dynamic workgroup sizing based on matrix dimensions");
    
    println!("4. Algorithmic Improvements:");
    println!("   - Implement register blocking for better cache reuse");
    println!("   - Use double buffering to hide memory latency");
    println!("   - Consider mixed-precision computation where appropriate");
}